import pandas as pd
import sys
import os
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score


sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from src.behavior_model import save_model

def train_and_save_model(data, save_path='saved_models/behavior_model.pkl'):
    """
    Train a RandomForest model to flag suspicious activity based on user behavior.
    Uses existing columns without generating synthetic ones.
    """
    # Check which columns exist in the dataset
    expected_columns = ['hour_of_day', 'day_of_week', 'activity_type', 'is_suspicious']
    for col in expected_columns:
        if col not in data.columns:
            raise ValueError(f"Missing required column: '{col}' in the dataset")

    # Preprocess data: Convert categorical data to dummy variables
    X = pd.get_dummies(data[['hour_of_day', 'day_of_week', 'activity_type']], drop_first=True)
    y = data['is_suspicious']

    # Split the data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Train the model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)

    # Evaluate the model
    y_pred = model.predict(X_test)
    print("\nModel Evaluation:")
    print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))

    # Save the trained model
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    save_model(model, save_path)
    print(f"Model saved successfully at '{save_path}'.")

if __name__ == "__main__":
    # File path for dataset and model
    data_file = 'user_activity_data.csv'
    model_save_path = 'saved_models/behavior_model.pkl'

    # Step 1: Verify data file exists
    if not os.path.exists(data_file):
        raise FileNotFoundError(f"Data file '{data_file}' not found. Please ensure it exists.")

    # Step 2: Load existing dataset
    data = pd.read_csv(data_file)
    print("\nDataset loaded successfully:")
    print(data.head())  # Display the first few rows for verification

    # Step 3: Train and save the model using existing columns
    train_and_save_model(data, model_save_path)
